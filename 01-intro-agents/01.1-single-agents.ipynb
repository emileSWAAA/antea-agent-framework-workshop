{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55c068c7",
   "metadata": {},
   "source": [
    "Introduction to Microsoft Agent Framework\n",
    "\n",
    "topics of the SK 2.1:\n",
    "1. One simple agent - done\n",
    "2. Dynamic agent instructions with template parameters (tbd)\n",
    "3. Multi-Turn Conversations - done\n",
    "4. EX1 - Simple Question-Answering Agent - too simple?\n",
    "5. Length of chat history in check - done\n",
    "6. Function calling and plugins - done\n",
    "7. Plugin example for agent - done\n",
    "8. Function invocation deep-dive - removed\n",
    "9. function calling modes - tbd\n",
    "10. EX2 - create your own plugin - changing to middleware\n",
    "11. agent that generates creative content and how streaming works - tbd\n",
    "12. static error handling - tbd\n",
    "\n",
    "\n",
    "the potential topics for 1.1 AF (single agent):\n",
    "1. simple agent and agent run options (and streaming)\n",
    "2. TBD [responses and messages](https://learn.microsoft.com/en-us/agent-framework/user-guide/agents/running-agents?pivots=programming-language-python)\n",
    "    [ChatMessage object example](https://learn.microsoft.com/en-us/agent-framework/tutorials/agents/run-agent?pivots=programming-language-python)\n",
    "\n",
    "3. [Multi-Turn Conversations and Threading](https://learn.microsoft.com/en-us/agent-framework/user-guide/agents/multi-turn-conversation?pivots=programming-language-python)\n",
    "    Added an example for [this](https://learn.microsoft.com/en-us/agent-framework/tutorials/agents/multi-turn-conversation?pivots=programming-language-python)\n",
    "\n",
    "4. TBD - introduce [AgentThread Storage and Custom Message Stores](https://learn.microsoft.com/en-us/agent-framework/user-guide/agents/multi-turn-conversation?pivots=programming-language-python) and [persisting agent conversations](https://learn.microsoft.com/en-us/agent-framework/tutorials/agents/persisted-conversation?pivots=programming-language-python) or [ChatMessage Store](https://learn.microsoft.com/en-us/agent-framework/tutorials/agents/third-party-chat-history-storage?pivots=programming-language-python) to align with SK 2.1 \"Keeping the length of the chat history in check\"\n",
    "\n",
    "\n",
    "5. Agent function tools - https://learn.microsoft.com/en-us/agent-framework/user-guide/agents/agent-tools?pivots=programming-language-python\n",
    "    Exercise to create an agent with function tools [based on this](https://learn.microsoft.com/en-us/agent-framework/tutorials/agents/function-tools?pivots=programming-language-python)\n",
    "\n",
    "\n",
    "6. Middleware - https://learn.microsoft.com/en-us/agent-framework/user-guide/agents/agent-middleware?pivots=programming-language-python\n",
    "    6.1 potential exercise to add logging functions https://learn.microsoft.com/en-us/agent-framework/tutorials/agents/middleware?pivots=programming-language-python\n",
    "\n",
    "7. Memory - https://learn.microsoft.com/en-us/agent-framework/user-guide/agents/agent-memory?pivots=programming-language-python\n",
    "    The tutorial seems more advanced\n",
    "\n",
    "8. Observability - https://learn.microsoft.com/en-us/agent-framework/user-guide/agents/agent-observability?pivots=programming-language-python\n",
    "\n",
    "Other topics TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c0a608",
   "metadata": {},
   "source": [
    "All agents are derived from a common base class, `AIAgent`, which provides a consistent interface for all agent types. \n",
    "\n",
    "Agent Framework supports many different types of agents. This tutorial shows you how to create and run an agent with Agent Framework based on the Azure OpenAI Chat Completion service, but all other agent types are run in the same way.\n",
    "\n",
    "These agents support a wide range of functionality out of the box:\n",
    "\n",
    "1. Function calling\n",
    "2. Multi-turn conversations with local chat history management or service provided chat history management\n",
    "3. Custom service provided tools (e.g. MCP, Code Execution)\n",
    "4. Structured output\n",
    "5. Streaming responses\n",
    "\n",
    "\n",
    "For more information on other agent types and how to construct them, see the [Agent Framework Agent Types](https://learn.microsoft.com/en-us/agent-framework/user-guide/agents/agent-types/?pivots=programming-language-python)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876825f9",
   "metadata": {},
   "source": [
    "### Our first Agent\n",
    "\n",
    "Now, let's build an single agent to get started. First, create a chat client for communicating with Azure OpenAI:\n",
    "\n",
    "```\n",
    "AZURE_OPENAI_ENDPOINT - The endpoint it should talk to by default\n",
    "AZURE_OPENAI_API_KEY - The API Key it should use\n",
    "AZURE_OPENAI_API_VERSION - Inference API version it should use per default\n",
    "AZURE_OPENAI_CHAT_DEPLOYMENT_NAME - Model deployment name it should use per default\n",
    "AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME - Embedding deployment name it should use per default\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a1a0595",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from agent_framework.azure import AzureOpenAIChatClient\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "deployment = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "\n",
    "# Create the client using API key\n",
    "client = AzureOpenAIChatClient(\n",
    "    endpoint=endpoint,\n",
    "    api_key=api_key,\n",
    "    api_version=api_version,\n",
    "    deployment_name=deployment\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9c6a59",
   "metadata": {},
   "source": [
    "Then, create the agent, providing instructions and a name for the agent. To run the agent, call the `.run()` method on the agent instance, providing the user input. \n",
    "\n",
    "The agent will return a response object, and accessing the .text property provides the text result from the agent.\n",
    "\n",
    "Please note that we do not have an chat history, so every message we send to the agent is treated as a new conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2b71d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_agent = client.create_agent(\n",
    "    instructions=\"You are an AI assistant that helps users with their questions.\",\n",
    "    name=\"AI Assistant\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9727c650",
   "metadata": {},
   "source": [
    "### Running the agent \n",
    "To run the agent, call the `run` method on the agent instance, providing the user input. The agent will return a response object, and accessing the `.text` property provides the text result from the agent.\n",
    "\n",
    "To run the agent with streaming, call the `run_stream` method on the agent instance, providing the user input. The agent will stream a list of update objects, and accessing the `.text` property on each update object provides the part of the text result contained in that update.\n",
    "\n",
    "Python agents support passing keyword arguments to customize each run. The specific options available depend on the agent type, but `ChatAgent` supports many chat client parameters that can be passed to both `run` and `run_stream` methods. Common options include `max_tokens`, `temperature`, `model`, `tools`, `response_format`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c95ee93a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full response: The capital of Latvia is Riga.\n",
      "\n",
      "Streaming response:\n",
      "Having a capital is important as it serves as the central location for a country's government and administration, facilitating effective governance and decision-making. Additionally, a capital\n"
     ]
    }
   ],
   "source": [
    "# Regular run\n",
    "response = await simple_agent.run(\"What's the capital of Latvia?\")\n",
    "print(\"Full response:\", response.text)\n",
    "\n",
    "# Streaming run\n",
    "print(\"\\nStreaming response:\")\n",
    "async for chunk in simple_agent.run_stream(\"Explain why having a capital for a country is important in two short sentences.\", \n",
    "                                           max_tokens=30):\n",
    "    # Each chunk is a partial piece of the model's output\n",
    "    if chunk.text:\n",
    "            print(chunk.text, end=\"\", flush=True)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288fa449",
   "metadata": {},
   "source": [
    "### Message Types and diferent content input examples\n",
    "simple overview so users know how to work and control those\n",
    "\n",
    "ChatMessage Object, Images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91396922",
   "metadata": {},
   "source": [
    "### Enabling Multi-Turn Conversations and Threading\n",
    "\n",
    "So far, our agents are stateless and do not maintain any state internally between calls. If you ask them a follow up question, they would have no reference to the prior conversation.\n",
    "\n",
    "To have a multi-turn conversation with an agent, you need to create an object to hold the conversation state and pass this object to the agent when running it.\n",
    "\n",
    "An `AgentThread` maintains the conversation state and message history for an agent interaction. It can either use a service-managed thread (via service_thread_id) or a local message store (via message_store), but not both.\n",
    "\n",
    "To create the conversation state object, call the `get_new_thread()` method on the agent instance.\n",
    "\n",
    "You can then pass this thread object to the `run` or `run_stream` methods on the agent instance, along with the user input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29461187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** User: Hello!\n",
      "*** Agent: Hello! How can I assist you today?\n",
      "*** User: Which country has Paris as the capital?\n",
      "*** Agent: Paris is the capital of France. If you have any more questions about France or anything else, feel free to ask!\n",
      "*** User: What are its neighbouring countries? Give a short one-liner list, please.\n",
      "*** Agent: France shares its borders with the following countries:\n",
      "\n",
      "1. Belgium\n",
      "2. Luxembourg\n",
      "3. Germany\n",
      "4. Switzerland\n",
      "5. Italy\n",
      "6. Monaco\n",
      "7. Spain\n",
      "8. Andorra\n",
      "9. Brazil (via Guiana)\n",
      "10. Suriname (via Guiana)\n",
      "\n",
      "If you need more information about any of these countries, just let me know!\n",
      "-------------------------\n",
      "[user] Hello!\n",
      "[assistant] Hello! How can I assist you today?\n",
      "[user] Which country has Paris as the capital?\n",
      "[assistant] Paris is the capital of France. If you have any more questions about France or anything else, feel free to ask!\n",
      "[user] What are its neighbouring countries? Give a short one-liner list, please.\n",
      "[assistant] France shares its borders with the following countries:\n",
      "\n",
      "1. Belgium\n",
      "2. Luxembourg\n",
      "3. Germany\n",
      "4. Switzerland\n",
      "5. Italy\n",
      "6. Monaco\n",
      "7. Spain\n",
      "8. Andorra\n",
      "9. Brazil (via Guiana)\n",
      "10. Suriname (via Guiana)\n",
      "\n",
      "If you need more information about any of these countries, just let me know!\n"
     ]
    }
   ],
   "source": [
    "agent = client.create_agent(\n",
    "    instructions=\"You are an AI assistant that helps users with their questions.\",\n",
    "    name=\"AI Assistant\"\n",
    ")\n",
    "\n",
    "# create a thread on the agent instance:\n",
    "thread = agent.get_new_thread()\n",
    "\n",
    "user_messages = [\n",
    "    \"Hello!\",\n",
    "    \"Which country has Paris as the capital?\",\n",
    "    \"What are its neighbouring countries? Give a short one-liner list, please.\"\n",
    "]\n",
    "\n",
    "# Loop through user messages and maintain context\n",
    "for user_message in user_messages:\n",
    "    print(\"*** User:\", user_message)\n",
    "    \n",
    "    # get response from the agent, passing the same thread\n",
    "    response = await agent.run(user_message, thread=thread)\n",
    "    print(\"*** Agent:\", response.text)\n",
    "\n",
    "print(\"-\" * 25)\n",
    "\n",
    "# Print the final conversation history from the thread\n",
    "messages = await thread.message_store.list_messages()\n",
    "for msg in messages:\n",
    "    print(f\"[{msg.role}] {msg.text}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24686014",
   "metadata": {},
   "source": [
    "### Single agent with multiple conversations\n",
    "\n",
    "It is possible to have multiple, independent conversations with the same agent instance, by creating multiple `AgentThread` objects. These threads can then be used to maintain separate conversation states for each conversation. The conversations will be fully independent of each other, since the agent does not maintain any state internally.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "996457e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread 1: Visit the Eiffel Tower for stunning views of the city and a quintessential Parisian experience.\n",
      "Thread 2: Visit the Senso-ji Temple in Asakusa, Tokyo’s oldest temple, known for its stunning architecture and lively Nakamise shopping street leading up to it.\n",
      "Thread 1: Stroll through the charming streets of Montmartre and enjoy a coffee at a local café while admiring the artistic vibe.\n",
      "Thread 2: Take a peaceful stroll through the tranquil Shinjuku Gyoen National Garden, surrounded by beautiful landscapes and seasonal blooms.\n"
     ]
    }
   ],
   "source": [
    "# Create two threads for two separate conversations\n",
    "thread1 = agent.get_new_thread()\n",
    "thread2 = agent.get_new_thread()\n",
    "\n",
    "# First messages for each thread\n",
    "result1 = await agent.run(\"Suggest 1 key attraction for Paris trip. Keep it brief.\", thread=thread1)\n",
    "print(\"Thread 1:\", result1.text)\n",
    "\n",
    "result2 = await agent.run(\"Suggest 1 key attraction for Tokyo trip. Keep it brief.\", thread=thread2)\n",
    "print(\"Thread 2:\", result2.text)\n",
    "\n",
    "# Continue each conversation independently\n",
    "result3 = await agent.run(\n",
    "    \"Now suggest one morning activity. One short sentence.\",\n",
    "    thread=thread1\n",
    ")\n",
    "print(\"Thread 1:\", result3.text)\n",
    "\n",
    "result4 = await agent.run(\n",
    "    \"Now suggest one morning activity. One short sentence.\",\n",
    "    thread=thread2\n",
    ")\n",
    "print(\"Thread 2:\", result4.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7889804",
   "metadata": {},
   "source": [
    "### Agent Tools\n",
    "Tooling support may vary considerably between different agent types. Some agents may allow developers to customize the agent at construction time by providing external function tools or by choosing to activate specific built-in tools that are supported by the agent. \n",
    "\n",
    "The `ChatAgent` is an agent class that can be used to build agentic capabilities on top of any inference service. It comes with support for:\n",
    "\n",
    "1. Using your own function tools with the agent\n",
    "2. Using built-in tools that the underlying service may support\n",
    "3. Using hosted tools like web search and MCP (Model Context Protocol) servers\n",
    "\n",
    "Let's try to provide function tools during agent construction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3eb24b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current time in New York is 16:34:48, and the weather is cloudy with a high of 15°C.\n"
     ]
    }
   ],
   "source": [
    "from typing import Annotated\n",
    "from agent_framework import ChatAgent\n",
    "from agent_framework.azure import AzureOpenAIChatClient\n",
    "from datetime import datetime\n",
    "\n",
    "def get_time() -> str:\n",
    "    return datetime.now().strftime(\"%H:%M:%S\")\n",
    "\n",
    "# Sample function tool\n",
    "def get_weather(\n",
    "    location: Annotated[str, \"The location to get the weather for.\"],\n",
    ") -> str:\n",
    "    \"\"\"Get the weather for a given location.\"\"\"\n",
    "    return f\"The weather in {location} is cloudy with a high of 15°C.\"\n",
    "\n",
    "# Agent with agent-level tool available  for all runs\n",
    "agent = ChatAgent(\n",
    "    chat_client=AzureOpenAIChatClient(),\n",
    "    instructions=\"You are a helpful assistant\",\n",
    "    tools=[get_time] \n",
    ")\n",
    "\n",
    "# This run has access to both get_time (agent-level) and get_weather (run-level)\n",
    "result = await agent.run(\n",
    "    \"What's the weather and time in New York?\",\n",
    "    tools=[get_weather]  # Additional tool for this run\n",
    ")\n",
    "\n",
    "print(result.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89f611f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** User: Hello!\n",
      "*** Agent: Hello! How can I assist you today?\n",
      "*** User: Please write a note saying 'Meeting with client at 3 PM'.\n",
      "*** Agent: I've written the note: \"Meeting with client at 3 PM\". If you need anything else, just let me know!\n",
      "*** User: Add another note: 'Prepare slides for tomorrow'.\n",
      "*** Agent: I've added the note: \"Prepare slides for tomorrow.\" Let me know if you need anything else!\n",
      "*** User: Can you list all my notes?\n",
      "*** Agent: Here are all your notes:\n",
      "\n",
      "1. **Meeting with client at 3 PM** - Timestamp: 2025-10-25 16:34:59\n",
      "2. **Prepare slides for tomorrow** - Timestamp: 2025-10-25 16:35:00\n",
      "\n",
      "If you need anything else, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "# You can also create a class that contains multiple function tools as methods. \n",
    "from typing import Annotated, List, Tuple\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "class NotesTools:\n",
    "    def __init__(self):\n",
    "        self.notes = []  # Store notes as (timestamp, note)\n",
    "\n",
    "    def list_notes(self) -> Annotated[List[Tuple[str, str]], \"Returns all notes as (timestamp, note).\"]:\n",
    "        \"\"\"Return all notes with their timestamps.\"\"\"\n",
    "        if not self.notes:\n",
    "            return \"No notes available.\"\n",
    "        return self.notes\n",
    "\n",
    "    def write_note(\n",
    "        self,\n",
    "        note: Annotated[str, \"The note message to save.\"],\n",
    "    ) -> str:\n",
    "        \"\"\"Save a note with the current timestamp.\"\"\"\n",
    "        timestamp = datetime.now().isoformat()\n",
    "        self.notes.append((timestamp, note))\n",
    "        return f\"Note added at {timestamp}.\"\n",
    "\n",
    "    \n",
    "# create tools instance\n",
    "tools = NotesTools()\n",
    "\n",
    "# create agent with tools\n",
    "agent = client.create_agent(\n",
    "    instructions=\"You are a helpful assistant that can take notes and show them.\",\n",
    "    tools=[tools.write_note, tools.list_notes]\n",
    ")\n",
    "\n",
    "# create a thread for multi-turn conversation\n",
    "thread = agent.get_new_thread()\n",
    "\n",
    "user_messages = [\n",
    "    \"Find new soup recipes.\",\n",
    "    \"Find new project opportunities at university.\",\n",
    "    \"Don't forget to call Jess to say happy birthday.\",\n",
    "    \"Can you list all my notes?\"\n",
    "]\n",
    "\n",
    "for m in user_messages:\n",
    "    print(\"*** User:\", m)\n",
    "    response = await agent.run(m, thread=thread)\n",
    "    print(\"*** Agent:\", response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb1b8ab",
   "metadata": {},
   "source": [
    "### TBD - Structured Output with Agents\n",
    "Sometimes it might be helpful to have our agent return its response in a fixed format. For this we can use the Response Format feature. This is similar to OpenAI's Structured Output feature and forces the model's output into a pre-defined structure:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a7476e",
   "metadata": {},
   "source": [
    "## Exercise - implement an agent with function tools\n",
    "\n",
    "In this exercise, you'll create an agent that manages tasks with priorities and deadlines. This will help you understand how to create and expose function tools to an agent and run a multi-turn conversation.\n",
    "\n",
    "#### Task:\n",
    "1. Create a `TaskManagerTools` class with the following functions:\n",
    "    - `add_task(name, priority, deadline)` - Adds a new task with a description, priority (high, medium, low), and deadline in DD-MM format.\n",
    "    - `list_tasks()` - Returns all tasks with their details.\n",
    "    - `filter_by_priority(priority)` - Returns tasks that match the given priority.\n",
    "\n",
    "2. Annotate parameters with `Annotated` to provide descriptions for better LLM understanding.\n",
    "3. Create an agent with clear instructions and register function tools\n",
    "4. Test the agent with a multi-turn conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "489005db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** User: Add a task to prepare workshop slides, high priority by 30.10\n",
      "*** Agent: The task to prepare workshop slides has been added with high priority and a deadline of 30.10.\n",
      "*** User: Send invites by december 30th\n",
      "*** Agent: The task to send invites has been added with medium priority and a deadline of December 30th.\n",
      "*** User: I need to send an email to Kate by nov 4\n",
      "*** Agent: The task to send an email to Kate has been added with medium priority and a deadline of November 4th.\n",
      "*** User: List all tasks.\n",
      "*** Agent: Here are all your tasks:\n",
      "\n",
      "1. **Prepare workshop slides**\n",
      "   - Priority: High\n",
      "   - Deadline: 30.10\n",
      "\n",
      "2. **Send invites**\n",
      "   - Priority: Medium\n",
      "   - Deadline: 30.12\n",
      "\n",
      "3. **Send email to Kate**\n",
      "   - Priority: Medium\n",
      "   - Deadline: 04.11\n",
      "*** User: Show me tasks with low priority.\n",
      "*** Agent: There are currently no tasks with low priority.\n"
     ]
    }
   ],
   "source": [
    "# will be hidden in HTML, here for test/review\n",
    "from typing import Annotated, List, Dict\n",
    "from datetime import datetime\n",
    "\n",
    "class TaskManagerTools:\n",
    "    def __init__(self):\n",
    "        self.tasks: List[Dict[str, str]] = []  # expected list of dicts, each task: {\"name\": str, \"priority\": str, \"deadline\": str}\n",
    "\n",
    "    def add_task(\n",
    "        self,\n",
    "        name: Annotated[str, \"The task description.\"],\n",
    "        priority: Annotated[str, \"Priority level: high, medium, low.\"],\n",
    "        deadline: Annotated[str, \"Deadline in format like 'September 30' or '30.10'.\"],\n",
    "    ) -> str:\n",
    "        \"\"\"Add a new task with priority and deadline (stored as DD-MM).\"\"\"\n",
    "        deadline_str = deadline  # Default to raw input\n",
    "        try:\n",
    "            # Try parsing \"September 30\" or \"30.10\"\n",
    "            if \".\" in deadline:  # Format like 30.10\n",
    "                parsed_date = datetime.strptime(deadline, \"%d-%m\")\n",
    "            else:  # Format like September 30\n",
    "                parsed_date = datetime.strptime(deadline, \"%B %d\")\n",
    "            deadline_str = parsed_date.strftime(\"%d-%m\")\n",
    "        except ValueError:\n",
    "            # If parsing fails, keep raw input\n",
    "            pass\n",
    "\n",
    "        self.tasks.append({\"name\": name, \"priority\": priority, \"deadline\": deadline_str})\n",
    "        return f\"Task '{name}' added with priority {priority} and deadline {deadline_str}.\"\n",
    "\n",
    "    def list_tasks(self) -> Annotated[List[Dict[str, str]], \"Returns all tasks with details.\"]:\n",
    "        \"\"\"List all tasks.\"\"\"\n",
    "        return self.tasks if self.tasks else \"No tasks available.\"\n",
    "\n",
    "    def filter_by_priority(\n",
    "        self,\n",
    "        priority: Annotated[str, \"Priority level to filter: high, medium, low.\"],\n",
    "    ) -> List[Dict[str, str]]:\n",
    "        \"\"\"Return tasks matching the given priority.\"\"\"\n",
    "        filtered = [task for task in self.tasks if task[\"priority\"] == priority]\n",
    "        return filtered if filtered else f\"No tasks with priority {priority}.\"\n",
    "\n",
    "\n",
    "# Create agent with tools\n",
    "tools = TaskManagerTools()\n",
    "\n",
    "agent = client.create_agent(\n",
    "    instructions=\"You are a helpful and precise assistant that manages tasks with priorities and deadlines.\",\n",
    "    tools=[tools.add_task, tools.list_tasks, tools.filter_by_priority]\n",
    ")\n",
    "\n",
    "# Multi-turn conversation\n",
    "thread = agent.get_new_thread()\n",
    "user_messages = [\n",
    "    \"Add a task to prepare workshop slides, high priority by 30.10\",\n",
    "    \"Send invites by december 30th\",\n",
    "    \"I need to send an email to Kate by nov 4\",\n",
    "    \"List all tasks.\",\n",
    "    \"Show me tasks with low priority.\"\n",
    "]\n",
    "\n",
    "for m in user_messages:\n",
    "    print(\"*** User:\", m)\n",
    "    response = await agent.run(m, thread=thread)\n",
    "    print(\"*** Agent:\", response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1aff74b",
   "metadata": {},
   "source": [
    "### Agent Middleware\n",
    "\n",
    "Middleware in the Agent Framework provides a powerful way to intercept, modify, and enhance agent interactions at various stages of execution. You can use middleware to implement cross-cutting concerns such as logging, security validation, error handling, and result transformation without modifying your core agent or function logic.\n",
    "\n",
    "Function-based middleware is the simplest way to implement middleware using async functions. This approach is ideal for stateless operations and provides a lightweight solution for common middleware scenarios.\n",
    "\n",
    "1. Agent Middleware\n",
    "2. Function Middleware\n",
    "3. Chat Middleware\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "128d81c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Agent] BEFORE execution\n",
      "[Function] Calling get_time\n",
      "[Function] get_time completed\n",
      "[Function] Result: 16:38:38\n",
      "[Agent] AFTER execution | Agent output: The current time is 16:38:38.\n",
      "Final response:  The current time is 16:38:38.\n",
      "----------------------------------\n",
      "[Agent] BEFORE execution\n",
      "[Agent] AFTER execution | Agent output: Of course! What do you need help with?\n",
      "Final response:  Of course! What do you need help with?\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from agent_framework import FunctionInvocationContext\n",
    "from typing import Callable, Awaitable\n",
    "from agent_framework import agent_middleware\n",
    "\n",
    "def get_time():\n",
    "    \"\"\"Get the current time.\"\"\"\n",
    "    return datetime.now().strftime(\"%H:%M:%S\")\n",
    "\n",
    "# middleware hooks onto function invocation events\n",
    "async def logging_function_middleware(\n",
    "    context: FunctionInvocationContext,\n",
    "    next: Callable[[FunctionInvocationContext], Awaitable[None]],\n",
    ") -> None:\n",
    "    \"\"\"Middleware that logs function execution.\"\"\"\n",
    "    print(f\"[Function] Calling {context.function.name}\")\n",
    "\n",
    "    await next(context) # executes the actual function or any next MW\n",
    "\n",
    "    print(f\"[Function] {context.function.name} completed\")\n",
    "    print(f\"[Function] Result: {context.result}\")\n",
    "\n",
    "\n",
    "# agent-level MW is applied to the entire agent run\n",
    "@agent_middleware  # Explicitly marks as agent middleware\n",
    "async def logging_agent_middleware(context, next):    # don't need to explicitly declare type annotations\n",
    "    \"\"\"Agent middleware with decorator - types are inferred.\"\"\"\n",
    "    print(f\"[Agent] BEFORE execution\")\n",
    "    await next(context)     # executes the agent logic\n",
    "    print(f\"[Agent] AFTER execution | Agent output: {context.result}\")\n",
    "\n",
    "agent = client.create_agent(\n",
    "    name=\"TimeAgent\",\n",
    "    instructions=\"You can tell the current time.\",\n",
    "    tools=[get_time],    \n",
    "    middleware=[logging_function_middleware, logging_agent_middleware]\n",
    ")\n",
    "\n",
    "result = await agent.run(\"What time is it?\")\n",
    "print(\"Final response: \", result.text)\n",
    "\n",
    "print(\"----------------------------------\")\n",
    "\n",
    "# the following response doesn't invoke get_time() so logging_function MW won't fire\n",
    "result = await agent.run(\n",
    "    \"Can you help?\"\n",
    ")\n",
    "\n",
    "print(\"Final response: \", result.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c651f7e6",
   "metadata": {},
   "source": [
    "### Example from SK where logging was added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7aee3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated, List, Optional\n",
    "\n",
    "class LightModel(TypedDict):\n",
    "    id: int\n",
    "    name: str\n",
    "    is_on: bool | None\n",
    "    brightness: int | None\n",
    "    hex: str | None\n",
    "\n",
    "class LightsTools:\n",
    "    def __init__(self, lights: list[LightModel]): # stores a list of lights in self.lights\n",
    "        self.lights = lights\n",
    "\n",
    "    def get_lights(self) -> List[LightModel]:                \n",
    "        \"\"\"Gets a list of lights and their current state.\"\"\"\n",
    "        return self.lights\n",
    "\n",
    "    def get_state(\n",
    "        self, id: Annotated[int, \"The ID of the light\"] #  Annotated adds documentation for LLMs\n",
    "    ) -> Optional[LightModel]:\n",
    "        \"\"\"Gets the state of a particular light.\"\"\"\n",
    "        for light in self.lights:\n",
    "            if light[\"id\"] == id:\n",
    "                return light\n",
    "        return None\n",
    "    \n",
    "    def change_state(\n",
    "        self, id: Annotated[int, \"The ID of the light\"], new_state: LightModel\n",
    "    ) -> dict:\n",
    "        \"\"\"Changes the state of the light and returns previous/current info.\"\"\"\n",
    "        for light in self.lights:\n",
    "            if light[\"id\"] == id:\n",
    "                previous = light.copy()  # snapshot before change\n",
    "                light[\"is_on\"] = new_state.get(\"is_on\", light[\"is_on\"])\n",
    "                light[\"brightness\"] = new_state.get(\"brightness\", light[\"brightness\"])\n",
    "                light[\"hex\"] = new_state.get(\"hex\", light[\"hex\"])\n",
    "                return {\n",
    "                    \"previous\": previous,\n",
    "                    \"current\": light\n",
    "                }\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f9dcfcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "lights = [\n",
    "    {\"id\": 1, \"name\": \"Table Lamp\", \"is_on\": False, \"brightness\": 100, \"hex\": \"FF0000\"},\n",
    "    {\"id\": 2, \"name\": \"Porch light\", \"is_on\": False, \"brightness\": 50, \"hex\": \"00FF00\"},\n",
    "    {\"id\": 3, \"name\": \"Chandelier\", \"is_on\": True, \"brightness\": 75, \"hex\": \"0000FF\"},\n",
    "]\n",
    "\n",
    "# data to instantiate a class and pass methods as tools\n",
    "tools = LightsTools(lights=lights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4f8ebc54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All lamps are already turned on, so no action is required.\n",
      "Final data: [{'id': 1, 'name': 'Table Lamp', 'is_on': True, 'brightness': 100, 'hex': 'FF0000'}, {'id': 2, 'name': 'Porch light', 'is_on': True, 'brightness': 50, 'hex': '00FF00'}, {'id': 3, 'name': 'Chandelier', 'is_on': True, 'brightness': 75, 'hex': '0000FF'}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "agent = client.create_agent(\n",
    "    instructions=\"\"\"\n",
    "    You control and manage smart lights.\n",
    "    - Check previous states to check if an action needs to be taken\n",
    "    - When turning lights on or off, do NOT change brightness or hex unless the user explicitly asks.\n",
    "    - When changing brightness or hex, only modify those values if requested.\"\"\",\n",
    "    tools=[tools.get_lights, tools.get_state, tools.change_state]\n",
    ")\n",
    "\n",
    "result = await agent.run(\n",
    "    \"turn on all lamps\",\n",
    "    )\n",
    "\n",
    "print(result)\n",
    "print(\"Final data:\", tools.lights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a948d9",
   "metadata": {},
   "source": [
    "In the following exercise, we'll be adding middleware for easier debugging and understanding of agent behavior, because currently we can't see anything besides agent's response.\n",
    "We'll add function middleware which intercepts function calls within agents, chat middleware dor OpenAI usage logging and agent-level middleware which is persistent across all runs for tool call counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aec56a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-25 17:01:30,846 - INFO - [Agent] Starting execution\n",
      "2025-10-25 17:01:30,846 - INFO - [Chat] Sending 2 messages to AI\n",
      "2025-10-25 17:01:31,757 - INFO - HTTP Request: POST https://semantic-kernel1.openai.azure.com/openai/deployments/sk-gpt-4o-mini/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-10-25 17:01:31,767 - INFO - [Chat] Response received\n",
      "2025-10-25 17:01:31,770 - INFO - [Function] Calling - get_lights | Args: \n",
      "2025-10-25 17:01:31,772 - INFO - Function name: get_lights\n",
      "2025-10-25 17:01:31,772 - INFO - Function get_lights succeeded.\n",
      "2025-10-25 17:01:31,781 - INFO - [Function] Completed \"get_lights\" in 0.006948s | Result: [{'id': 1, 'name': 'Table Lamp', 'is_on': True, 'brightness': 100, 'hex': 'FF0000'}, {'id': 2, 'name': 'Porch light', 'is_on': True, 'brightness': 50, 'hex': '00FF00'}, {'id': 3, 'name': 'Chandelier', 'is_on': True, 'brightness': 75, 'hex': '0000FF'}]\n",
      "2025-10-25 17:01:31,784 - INFO - [Chat] Sending 4 messages to AI\n",
      "2025-10-25 17:01:33,231 - INFO - HTTP Request: POST https://semantic-kernel1.openai.azure.com/openai/deployments/sk-gpt-4o-mini/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-10-25 17:01:33,235 - INFO - [Chat] Response received\n",
      "2025-10-25 17:01:33,238 - INFO - [Function] Calling - change_state | Args: id=1 new_state={'id': 1, 'name': 'Table Lamp', 'is_on': False, 'brightness': 100, 'hex': 'FF0000'}\n",
      "2025-10-25 17:01:33,240 - INFO - Function name: change_state\n",
      "2025-10-25 17:01:33,242 - INFO - Function change_state succeeded.\n",
      "2025-10-25 17:01:33,244 - INFO - [Function] Completed \"change_state\" in 0.003915s | Result: {'previous': {'id': 1, 'name': 'Table Lamp', 'is_on': True, 'brightness': 100, 'hex': 'FF0000'}, 'current': {'id': 1, 'name': 'Table Lamp', 'is_on': False, 'brightness': 100, 'hex': 'FF0000'}}\n",
      "2025-10-25 17:01:33,247 - INFO - [Function] Calling - change_state | Args: id=2 new_state={'id': 2, 'name': 'Porch light', 'is_on': False, 'brightness': 50, 'hex': '00FF00'}\n",
      "2025-10-25 17:01:33,249 - INFO - Function name: change_state\n",
      "2025-10-25 17:01:33,252 - INFO - Function change_state succeeded.\n",
      "2025-10-25 17:01:33,252 - INFO - [Function] Completed \"change_state\" in 0.006935s | Result: {'previous': {'id': 2, 'name': 'Porch light', 'is_on': True, 'brightness': 50, 'hex': '00FF00'}, 'current': {'id': 2, 'name': 'Porch light', 'is_on': False, 'brightness': 50, 'hex': '00FF00'}}\n",
      "2025-10-25 17:01:33,252 - INFO - [Function] Calling - change_state | Args: id=3 new_state={'id': 3, 'name': 'Chandelier', 'is_on': False, 'brightness': 75, 'hex': '0000FF'}\n",
      "2025-10-25 17:01:33,252 - INFO - Function name: change_state\n",
      "2025-10-25 17:01:33,263 - INFO - Function change_state succeeded.\n",
      "2025-10-25 17:01:33,265 - INFO - [Function] Completed \"change_state\" in 0.004631s | Result: {'previous': {'id': 3, 'name': 'Chandelier', 'is_on': True, 'brightness': 75, 'hex': '0000FF'}, 'current': {'id': 3, 'name': 'Chandelier', 'is_on': False, 'brightness': 75, 'hex': '0000FF'}}\n",
      "2025-10-25 17:01:33,267 - INFO - [Chat] Sending 6 messages to AI\n",
      "2025-10-25 17:01:34,521 - INFO - HTTP Request: POST https://semantic-kernel1.openai.azure.com/openai/deployments/sk-gpt-4o-mini/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-10-25 17:01:34,521 - INFO - [Chat] Response received\n",
      "2025-10-25 17:01:34,531 - INFO - [Agent] Agent run completed in 3.6844s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant >All lights have been turned off. Here are their final states:\n",
      "\n",
      "1. **Table Lamp**\n",
      "   - Previous State: On\n",
      "   - Current State: Off\n",
      "   - Brightness: 100\n",
      "   - Hex: FF0000\n",
      "\n",
      "2. **Porch Light**\n",
      "   - Previous State: On\n",
      "   - Current State: Off\n",
      "   - Brightness: 50\n",
      "   - Hex: 00FF00\n",
      "\n",
      "3. **Chandelier**\n",
      "   - Previous State: On\n",
      "   - Current State: Off\n",
      "   - Brightness: 75\n",
      "   - Hex: 0000FF\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import time\n",
    "from agent_framework import function_middleware, agent_middleware, chat_middleware\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\", force=True\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "@agent_middleware       # decorator allows to skip type annotations like AgentRunContext\n",
    "async def agent_middleware(context,next                           \n",
    ") -> None:\n",
    "    start = time.perf_counter()\n",
    "\n",
    "    logger.info(f\"[Agent] Starting execution\")\n",
    "\n",
    "    await next(context)\n",
    "\n",
    "    # Calculate total duration\n",
    "    duration = time.perf_counter() - start\n",
    "    logger.info(f\"[Agent] Agent run completed in {duration:.4f}s\")\n",
    "\n",
    "@chat_middleware \n",
    "async def chat_middleware(context, next\n",
    ") -> None:\n",
    "    logger.info(f\"[Chat] Sending {len(context.messages)} messages to AI\")\n",
    "\n",
    "    await next(context)\n",
    "\n",
    "    logger.info(\"[Chat] Response received\")\n",
    "\n",
    "@function_middleware        \n",
    "async def function_middleware(context, next\n",
    ") -> None:\n",
    "    logger.info(f\"[Function] Calling - {context.function.name} | Args: {context.arguments}\")\n",
    "    start = time.perf_counter()\n",
    "\n",
    "    await next(context)\n",
    "\n",
    "    duration = time.perf_counter() - start\n",
    "    logger.info(f\"[Function] Completed \\\"{context.function.name}\\\" in {duration:.6f}s | Result: {context.result}\")\n",
    "\n",
    "\n",
    "agent = client.create_agent(\n",
    "    instructions=\"\"\"\n",
    "    You control and manage smart lights.\n",
    "    - Check previous states to check if an action needs to be taken\n",
    "    - When turning lights on or off, do NOT change brightness or hex unless the user explicitly asks.\n",
    "    - When changing brightness or hex, only modify those values if requested.\"\"\",\n",
    "    tools=[tools.get_lights, tools.get_state, tools.change_state],\n",
    "    middleware=[agent_middleware, chat_middleware, function_middleware]\n",
    ")\n",
    "\n",
    "result = await agent.run(\n",
    "    \"turn off all lights and give me their final state\"\n",
    "    )\n",
    "\n",
    "print(\"Assistant >\" + str(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5264af",
   "metadata": {},
   "source": [
    "### TO-DO Exercise adding middleware to agents \n",
    "Based on SK's 1.1 \"Creating a Content Filter\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70105f17",
   "metadata": {},
   "source": [
    "### TO-DO Exercise Create Your Own Function Tools\n",
    "Based on SK's 2.1 \"Create Your Own Plugin\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent-framework-workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
