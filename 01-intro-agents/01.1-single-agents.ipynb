{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55c068c7",
   "metadata": {},
   "source": [
    "Introduction to Microsoft Agent Framework\n",
    "\n",
    "topics of the SK 2.1:\n",
    "1. One simple agent - done\n",
    "2. Dynamic agent instructions with template parameters (tbd)\n",
    "3. Multi-Turn Conversations - done\n",
    "4. EX1 - Simple Question-Answering Agent - too simple?\n",
    "5. Length of chat history in check - done\n",
    "6. Function calling and plugins - done\n",
    "7. Plugin example for agent - done\n",
    "8. Function invocation deep-dive - removed\n",
    "9. function calling modes - tbd\n",
    "10. EX2 - create your own plugin\n",
    "11. agent that generates creative content and how streaming works - tbd\n",
    "12. static error handling - tbd\n",
    "\n",
    "\n",
    "the potential topics for 1.1 AF (single agent):\n",
    "1. simple agent and agent run options (and streaming)\n",
    "2. TBD [responses and messages](https://learn.microsoft.com/en-us/agent-framework/user-guide/agents/running-agents?pivots=programming-language-python)\n",
    "    [ChatMessage object example](https://learn.microsoft.com/en-us/agent-framework/tutorials/agents/run-agent?pivots=programming-language-python)\n",
    "\n",
    "3. [Multi-Turn Conversations and Threading](https://learn.microsoft.com/en-us/agent-framework/user-guide/agents/multi-turn-conversation?pivots=programming-language-python)\n",
    "    Added an example for [this](https://learn.microsoft.com/en-us/agent-framework/tutorials/agents/multi-turn-conversation?pivots=programming-language-python)\n",
    "\n",
    "4. TBD - introduce [AgentThread Storage and Custom Message Stores](https://learn.microsoft.com/en-us/agent-framework/user-guide/agents/multi-turn-conversation?pivots=programming-language-python) and [persisting agent conversations](https://learn.microsoft.com/en-us/agent-framework/tutorials/agents/persisted-conversation?pivots=programming-language-python) or [ChatMessage Store](https://learn.microsoft.com/en-us/agent-framework/tutorials/agents/third-party-chat-history-storage?pivots=programming-language-python) to align with SK 2.1 \"Keeping the length of the chat history in check\"\n",
    "\n",
    "\n",
    "5. Agent function tools - https://learn.microsoft.com/en-us/agent-framework/user-guide/agents/agent-tools?pivots=programming-language-python\n",
    "    Exercise to create an agent with function tools [based on this](https://learn.microsoft.com/en-us/agent-framework/tutorials/agents/function-tools?pivots=programming-language-python)\n",
    "    TODO: Translate SK \"Create your own plugin\" to AF\n",
    "\n",
    "6. Middleware - https://learn.microsoft.com/en-us/agent-framework/user-guide/agents/agent-middleware?pivots=programming-language-python\n",
    "    TODO: SK1.1 \"Create content filter\" to middleware \n",
    "\n",
    "\n",
    "TODO (27.10) - add documentation and text guides based on [AF readme](https://github.com/microsoft/Agent-Framework-Samples?tab=readme-ov-file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c0a608",
   "metadata": {},
   "source": [
    "All agents are derived from a common base class, `AIAgent`, which provides a consistent interface for all agent types. \n",
    "\n",
    "Agent Framework supports many different types of agents. This tutorial shows you how to create and run an agent with Agent Framework based on the Azure OpenAI Chat Completion service, but all other agent types are run in the same way.\n",
    "\n",
    "\n",
    "These agents support a wide range of functionality out of the box:\n",
    "\n",
    "1. Function calling\n",
    "2. Multi-turn conversations with local chat history management or service provided chat history management\n",
    "3. Custom service provided tools (e.g. MCP, Code Execution)\n",
    "4. Structured output\n",
    "5. Streaming responses\n",
    "\n",
    "\n",
    "For more information on other agent types and how to construct them, see the [Agent Framework Agent Types](https://learn.microsoft.com/en-us/agent-framework/user-guide/agents/agent-types/?pivots=programming-language-python)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876825f9",
   "metadata": {},
   "source": [
    "### Our first Agent\n",
    "\n",
    "Now, let's build an single agent to get started. First, create a chat client for communicating with Azure OpenAI:\n",
    "\n",
    "```\n",
    "AZURE_OPENAI_ENDPOINT - The endpoint it should talk to by default\n",
    "AZURE_OPENAI_API_KEY - The API Key it should use\n",
    "AZURE_OPENAI_API_VERSION - Inference API version it should use per default\n",
    "AZURE_OPENAI_CHAT_DEPLOYMENT_NAME - Model deployment name it should use per default\n",
    "AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME - Embedding deployment name it should use per default\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a1a0595",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from agent_framework.azure import AzureOpenAIChatClient\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "deployment = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "\n",
    "# Create the client using API key\n",
    "client = AzureOpenAIChatClient(\n",
    "    endpoint=endpoint,\n",
    "    api_key=api_key,\n",
    "    api_version=api_version,\n",
    "    deployment_name=deployment\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9c6a59",
   "metadata": {},
   "source": [
    "Then, create the agent, providing instructions and a name for the agent. To run the agent, call the `.run()` method on the agent instance, providing the user input. \n",
    "\n",
    "The agent will return a response object, and accessing the .text property provides the text result from the agent.\n",
    "\n",
    "Please note that we do not have an chat history, so every message we send to the agent is treated as a new conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2b71d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_agent = client.create_agent(\n",
    "    instructions=\"You are an AI assistant that helps users with their questions.\",\n",
    "    name=\"AI Assistant\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9727c650",
   "metadata": {},
   "source": [
    "### Running the agent \n",
    "To run the agent, call the `run` method on the agent instance, providing the user input. The agent will return a response object, and accessing the `.text` property provides the text result from the agent.\n",
    "\n",
    "To run the agent with streaming, call the `run_stream` method on the agent instance, providing the user input. The agent will stream a list of update objects, and accessing the `.text` property on each update object provides the part of the text result contained in that update.\n",
    "\n",
    "Python agents support passing keyword arguments to customize each run. The specific options available depend on the agent type, but `ChatAgent` supports many chat client parameters that can be passed to both `run` and `run_stream` methods. Common options include `max_tokens`, `temperature`, `model`, `tools`, `response_format`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c95ee93a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full response: The capital of Latvia is Riga.\n",
      "\n",
      "Streaming response:\n",
      "A capital city serves as the political and administrative center of a country, providing a location for government institutions and decision-making processes. It also fosters national identity\n"
     ]
    }
   ],
   "source": [
    "# Regular run\n",
    "response = await simple_agent.run(\"What's the capital of Latvia?\")\n",
    "print(\"Full response:\", response.text)\n",
    "\n",
    "# Streaming run\n",
    "print(\"\\nStreaming response:\")\n",
    "async for chunk in simple_agent.run_stream(\"Explain why having a capital for a country is important in two short sentences.\", \n",
    "        max_tokens=30):\n",
    "    # Each chunk is a partial piece of the model's output\n",
    "    if chunk.text:\n",
    "            print(chunk.text, end=\"\", flush=True)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288fa449",
   "metadata": {},
   "source": [
    "### Message Types and diferent content input examples\n",
    "simple overview so users know how to work and control those\n",
    "\n",
    "ChatMessage Object, Images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91396922",
   "metadata": {},
   "source": [
    "### Enabling Multi-Turn Conversations and Threading\n",
    "\n",
    "So far, our agents are stateless and do not maintain any state internally between calls. If you ask them a follow up question, they would have no reference to the prior conversation.\n",
    "\n",
    "To have a multi-turn conversation with an agent, you need to create an object to hold the conversation state and pass this object to the agent when running it.\n",
    "\n",
    "An `AgentThread` maintains the conversation state and message history for an agent interaction. It can either use a service-managed thread (via service_thread_id) or a local message store (via message_store), but not both.\n",
    "\n",
    "To create the conversation state object, call the `get_new_thread()` method on the agent instance.\n",
    "\n",
    "You can then pass this thread object to the `run` or `run_stream` methods on the agent instance, along with the user input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29461187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** User: Hello!\n",
      "*** Agent: Hello! How can I assist you today?\n",
      "*** User: Which country has Paris as the capital?\n",
      "*** Agent: Paris is the capital of France. If you have any more questions about France or anything else, feel free to ask!\n",
      "*** User: What are its neighbouring countries? Give a short one-liner list, please.\n",
      "*** Agent: France shares its borders with the following countries:\n",
      "\n",
      "1. Belgium\n",
      "2. Luxembourg\n",
      "3. Germany\n",
      "4. Switzerland\n",
      "5. Italy\n",
      "6. Spain\n",
      "7. Monaco\n",
      "8. Netherlands (via maritime boundary)\n",
      "9. Andorra (via maritime boundary)\n",
      "\n",
      "If you need more information on any of these countries, let me know!\n",
      "-------------------------\n",
      "[user] Hello!\n",
      "[assistant] Hello! How can I assist you today?\n",
      "[user] Which country has Paris as the capital?\n",
      "[assistant] Paris is the capital of France. If you have any more questions about France or anything else, feel free to ask!\n",
      "[user] What are its neighbouring countries? Give a short one-liner list, please.\n",
      "[assistant] France shares its borders with the following countries:\n",
      "\n",
      "1. Belgium\n",
      "2. Luxembourg\n",
      "3. Germany\n",
      "4. Switzerland\n",
      "5. Italy\n",
      "6. Spain\n",
      "7. Monaco\n",
      "8. Netherlands (via maritime boundary)\n",
      "9. Andorra (via maritime boundary)\n",
      "\n",
      "If you need more information on any of these countries, let me know!\n"
     ]
    }
   ],
   "source": [
    "agent = client.create_agent(\n",
    "    instructions=\"You are an AI assistant that helps users with their questions.\",\n",
    "    name=\"AI Assistant\"\n",
    ")\n",
    "\n",
    "# create a thread on the agent instance:\n",
    "thread = agent.get_new_thread()\n",
    "\n",
    "user_messages = [\n",
    "    \"Hello!\",\n",
    "    \"Which country has Paris as the capital?\",\n",
    "    \"What are its neighbouring countries? Give a short one-liner list, please.\"\n",
    "]\n",
    "\n",
    "# Loop through user messages and maintain context\n",
    "for user_message in user_messages:\n",
    "    print(\"*** User:\", user_message)\n",
    "    \n",
    "    # get response from the agent, passing the same thread\n",
    "    response = await agent.run(user_message, thread=thread)\n",
    "    print(\"*** Agent:\", response.text)\n",
    "\n",
    "print(\"-\" * 25)\n",
    "\n",
    "# Print the final conversation history from the thread\n",
    "messages = await thread.message_store.list_messages()\n",
    "for msg in messages:\n",
    "    print(f\"[{msg.role}] {msg.text}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24686014",
   "metadata": {},
   "source": [
    "### Single agent with multiple conversations\n",
    "\n",
    "It is possible to have multiple, independent conversations with the same agent instance, by creating multiple `AgentThread` objects. These threads can then be used to maintain separate conversation states for each conversation. The conversations will be fully independent of each other, since the agent does not maintain any state internally.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "996457e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread 1: Visit the Eiffel Tower for breathtaking views of the city and a quintessential Parisian experience.\n",
      "Thread 2: Visit the Senso-ji Temple in Asakusa, Tokyo's oldest temple, known for its picturesque entrance gate, vibrant shopping street, and serene atmosphere, offering a glimpse into Japan's rich cultural heritage.\n",
      "Thread 1: Stroll through the charming streets of Montmartre and visit the iconic Basilica of Sacré-Cœur.\n",
      "Thread 2: Take a stroll through the tranquil Shinjuku Gyoen National Garden to enjoy its beautiful landscapes and seasonal flowers.\n"
     ]
    }
   ],
   "source": [
    "# Create two threads for two separate conversations\n",
    "thread1 = agent.get_new_thread()\n",
    "thread2 = agent.get_new_thread()\n",
    "\n",
    "# First messages for each thread\n",
    "result1 = await agent.run(\"Suggest 1 key attraction for Paris trip. Keep it brief.\", thread=thread1)\n",
    "print(\"Thread 1:\", result1.text)\n",
    "\n",
    "result2 = await agent.run(\"Suggest 1 key attraction for Tokyo trip. Keep it brief.\", thread=thread2)\n",
    "print(\"Thread 2:\", result2.text)\n",
    "\n",
    "# Continue each conversation independently\n",
    "result3 = await agent.run(\n",
    "    \"Now suggest one morning activity. One short sentence.\",\n",
    "    thread=thread1\n",
    ")\n",
    "print(\"Thread 1:\", result3.text)\n",
    "\n",
    "result4 = await agent.run(\n",
    "    \"Now suggest one morning activity. One short sentence.\",\n",
    "    thread=thread2\n",
    ")\n",
    "print(\"Thread 2:\", result4.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7889804",
   "metadata": {},
   "source": [
    "### Agent Tools\n",
    "Tooling support may vary considerably between different agent types. Some agents may allow developers to customize the agent at construction time by providing external function tools or by choosing to activate specific built-in tools that are supported by the agent. \n",
    "\n",
    "The `ChatAgent` is an agent class that can be used to build agentic capabilities on top of any inference service. It comes with support for:\n",
    "\n",
    "1. Using your own function tools with the agent\n",
    "2. Using built-in tools that the underlying service may support\n",
    "3. Using hosted tools like web search and MCP (Model Context Protocol) servers\n",
    "\n",
    "Let's try to provide function tools during agent construction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3eb24b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current weather in New York is cloudy with a high of 15°C. The time is 19:40.\n"
     ]
    }
   ],
   "source": [
    "from typing import Annotated\n",
    "from agent_framework import ChatAgent\n",
    "from agent_framework.azure import AzureOpenAIChatClient\n",
    "from datetime import datetime\n",
    "\n",
    "def get_time() -> str:\n",
    "    return datetime.now().strftime(\"%H:%M:%S\")\n",
    "\n",
    "# Sample function tool\n",
    "def get_weather(\n",
    "    location: Annotated[str, \"The location to get the weather for.\"],\n",
    ") -> str:\n",
    "    \"\"\"Get the weather for a given location.\"\"\"\n",
    "    return f\"The weather in {location} is cloudy with a high of 15°C.\"\n",
    "\n",
    "# Agent with agent-level tool available  for all runs\n",
    "agent = ChatAgent(\n",
    "    chat_client=AzureOpenAIChatClient(),\n",
    "    instructions=\"You are a helpful assistant\",\n",
    "    tools=[get_time] \n",
    ")\n",
    "\n",
    "# This run has access to both get_time (agent-level) and get_weather (run-level)\n",
    "result = await agent.run(\n",
    "    \"What's the weather and time in New York?\",\n",
    "    tools=[get_weather]  # Additional tool for this run\n",
    ")\n",
    "\n",
    "print(result.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f89f611f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** User: Find new soup recipes.\n",
      "*** Agent: I've logged your note to find new soup recipes. If you have any more notes or requests, feel free to share!\n",
      "*** User: Find new project opportunities at university.\n",
      "*** Agent: I've logged your note to find new project opportunities at university. Let me know if there's anything else you'd like to note!\n",
      "*** User: Don't forget to call Jess to say happy birthday.\n",
      "*** Agent: I've noted that you need to call Jess to wish her a happy birthday. If you have more notes or tasks, just let me know!\n",
      "*** User: Can you list all my notes?\n",
      "*** Agent: Here are all your notes:\n",
      "\n",
      "1. **2025-10-27 19:40:11** - Find new soup recipes.\n",
      "2. **2025-10-27 19:40:13** - Find new project opportunities at university.\n",
      "3. **2025-10-27 19:40:15** - Call Jess to say happy birthday.\n",
      "\n",
      "If you need anything else, just let me know!\n"
     ]
    }
   ],
   "source": [
    "# You can also create a class that contains multiple function tools as methods. \n",
    "from typing import Annotated, List, Tuple\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "class NotesTools:\n",
    "    def __init__(self):\n",
    "        self.notes = []  # Store notes as (timestamp, note)\n",
    "\n",
    "    def list_notes(self) -> Annotated[List[Tuple[str, str]], \"Returns all notes as (timestamp, note).\"]:\n",
    "        \"\"\"Return all notes with their timestamps.\"\"\"\n",
    "        if not self.notes:\n",
    "            return \"No notes available.\"\n",
    "        return self.notes\n",
    "\n",
    "    def write_note(\n",
    "        self,\n",
    "        note: Annotated[str, \"The note message to save.\"],\n",
    "    ) -> str:\n",
    "        \"\"\"Save a note with the current timestamp.\"\"\"\n",
    "        timestamp = datetime.now().isoformat()\n",
    "        self.notes.append((timestamp, note))\n",
    "        return f\"Note added at {timestamp}.\"\n",
    "\n",
    "    \n",
    "# create tools instance\n",
    "tools = NotesTools()\n",
    "\n",
    "# create agent with tools\n",
    "agent = client.create_agent(\n",
    "    instructions=\"You are an assistant that logs, stores notes and shows them. Everything i send is a note i want you to log in my notebook.\",\n",
    "    tools=[tools.write_note, tools.list_notes]\n",
    ")\n",
    "\n",
    "# create a thread for multi-turn conversation\n",
    "thread = agent.get_new_thread()\n",
    "\n",
    "user_messages = [\n",
    "    \"Find new soup recipes.\",\n",
    "    \"Find new project opportunities at university.\",\n",
    "    \"Don't forget to call Jess to say happy birthday.\",\n",
    "    \"Can you list all my notes?\"\n",
    "]\n",
    "\n",
    "for m in user_messages:\n",
    "    print(\"*** User:\", m)\n",
    "    response = await agent.run(m, thread=thread)\n",
    "    print(\"*** Agent:\", response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce38602",
   "metadata": {},
   "source": [
    "### TBD - Structured Output with Agents\n",
    "From SK 2.1\n",
    "\n",
    "Sometimes it might be helpful to have our agent return its response in a fixed format. For this we can use the Response Format feature. This is similar to OpenAI's Structured Output feature and forces the model's output into a pre-defined structure:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a7476e",
   "metadata": {},
   "source": [
    "## Exercise - implement an agent with function tools\n",
    "\n",
    "In this exercise, you'll create an agent that manages tasks with priorities and deadlines. This will help you understand how to create and expose function tools to an agent and run a multi-turn conversation.\n",
    "\n",
    "#### Task:\n",
    "1. Create a `TaskManagerTools` class with the following functions:\n",
    "    - `add_task(name, priority, deadline)` - Adds a new task with a description, priority (high, medium, low), and deadline in DD-MM format.\n",
    "    - `list_tasks()` - Returns all tasks with their details.\n",
    "    - `filter_by_priority(priority)` - Returns tasks that match the given priority.\n",
    "\n",
    "2. Annotate parameters with `Annotated` to provide descriptions for better LLM understanding.\n",
    "3. Create an agent with clear instructions and register function tools\n",
    "4. Test the agent with a multi-turn conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "489005db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** User: Add a task to prepare workshop slides, high priority by 30.10\n",
      "*** Agent: The task \"Prepare workshop slides\" has been added with high priority and a deadline of 30.10.\n",
      "*** User: Send invites by december 30th\n",
      "*** Agent: The task \"Send invites\" has been added with medium priority and a deadline of 30.12.\n",
      "*** User: I need to send an email to Kate by nov 4\n",
      "*** Agent: The task \"Send email to Kate\" has been added with medium priority and a deadline of 04.11.\n",
      "*** User: List all tasks.\n",
      "*** Agent: Here are all your tasks:\n",
      "\n",
      "1. **Prepare workshop slides**\n",
      "   - Priority: High\n",
      "   - Deadline: 30.10\n",
      "\n",
      "2. **Send email to Kate**\n",
      "   - Priority: Medium\n",
      "   - Deadline: 04.11\n",
      "\n",
      "3. **Send invites**\n",
      "   - Priority: Medium\n",
      "   - Deadline: 30.12\n",
      "*** User: Show me tasks with low priority.\n",
      "*** Agent: There are no tasks with low priority at the moment.\n"
     ]
    }
   ],
   "source": [
    "# will be hidden in HTML, here for test/review\n",
    "from typing import Annotated, List, Dict\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "class TaskManagerTools:\n",
    "    def __init__(self):\n",
    "        self.tasks: List[Dict[str, str]] = []  # expected list of dicts, each task: {\"name\": str, \"priority\": str, \"deadline\": str}\n",
    "\n",
    "    def add_task(\n",
    "        self,\n",
    "        name: Annotated[str, \"The task description.\"],\n",
    "        priority: Annotated[str, \"Priority level: high, medium, low.\"],\n",
    "        deadline: Annotated[str, \"Deadline in format like 'September 30' or '30.10'.\"],\n",
    "    ) -> str:\n",
    "        \"\"\"Add a new task with priority and deadline (stored as DD-MM).\"\"\"\n",
    "        deadline_str = deadline  # Default to raw input\n",
    "        try:\n",
    "            # Try parsing \"September 30\" or \"30.10\"\n",
    "            if \".\" in deadline:  # Format like 30.10\n",
    "                parsed_date = datetime.strptime(deadline, \"%d-%m\")\n",
    "            else:  # Format like September 30\n",
    "                parsed_date = datetime.strptime(deadline, \"%B %d\")\n",
    "            deadline_str = parsed_date.strftime(\"%d-%m\")\n",
    "        except ValueError:\n",
    "            # If parsing fails, keep raw input\n",
    "            pass\n",
    "\n",
    "        self.tasks.append({\"name\": name, \"priority\": priority, \"deadline\": deadline_str})\n",
    "        return f\"Task '{name}' added with priority {priority} and deadline {deadline_str}.\"\n",
    "\n",
    "    def list_tasks(self) -> Annotated[List[Dict[str, str]], \"Returns all tasks with details.\"]:\n",
    "        \"\"\"List all tasks.\"\"\"\n",
    "        return self.tasks if self.tasks else \"No tasks available.\"\n",
    "\n",
    "    def filter_by_priority(\n",
    "        self,\n",
    "        priority: Annotated[str, \"Priority level to filter: high, medium, low.\"],\n",
    "    ) -> List[Dict[str, str]]:\n",
    "        \"\"\"Return tasks matching the given priority.\"\"\"\n",
    "        filtered = [task for task in self.tasks if task[\"priority\"] == priority]\n",
    "        return filtered if filtered else f\"No tasks with priority {priority}.\"\n",
    "\n",
    "\n",
    "# Create agent with tools\n",
    "tools = TaskManagerTools()\n",
    "\n",
    "agent = client.create_agent(\n",
    "    instructions=\"You are a helpful and precise assistant that manages tasks with priorities and deadlines.\",\n",
    "    tools=[tools.add_task, tools.list_tasks, tools.filter_by_priority]\n",
    ")\n",
    "\n",
    "# Multi-turn conversation\n",
    "thread = agent.get_new_thread()\n",
    "user_messages = [\n",
    "    \"Add a task to prepare workshop slides, high priority by 30.10\",\n",
    "    \"Send invites by december 30th\",\n",
    "    \"I need to send an email to Kate by nov 4\",\n",
    "    \"List all tasks.\",\n",
    "    \"Show me tasks with low priority.\"\n",
    "]\n",
    "\n",
    "for m in user_messages:\n",
    "    print(\"*** User:\", m)\n",
    "    response = await agent.run(m, thread=thread)\n",
    "    print(\"*** Agent:\", response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1aff74b",
   "metadata": {},
   "source": [
    "### Agent Middleware\n",
    "\n",
    "Middleware in the Agent Framework provides a powerful way to intercept, modify, and enhance agent interactions at various stages of execution. You can use middleware to implement cross-cutting concerns such as logging, security validation, error handling, and result transformation without modifying your core agent or function logic.\n",
    "\n",
    "Function-based middleware is the simplest way to implement middleware using async functions. This approach is ideal for stateless operations and provides a lightweight solution for common middleware scenarios.\n",
    "\n",
    "1. Agent Middleware\n",
    "2. Function Middleware\n",
    "3. Chat Middleware\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "128d81c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Agent] BEFORE execution\n",
      "[Function] Calling get_time\n",
      "[Function] get_time completed\n",
      "[Function] Result: 19:40:36\n",
      "[Agent] AFTER execution | Agent output: The current time is 19:40:36.\n",
      "Final response:  The current time is 19:40:36.\n",
      "----------------------------------\n",
      "[Agent] BEFORE execution\n",
      "[Agent] AFTER execution | Agent output: Of course! How can I assist you today?\n",
      "Final response:  Of course! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from agent_framework import FunctionInvocationContext\n",
    "from typing import Callable, Awaitable\n",
    "from agent_framework import agent_middleware\n",
    "\n",
    "def get_time():\n",
    "    \"\"\"Get the current time.\"\"\"\n",
    "    return datetime.now().strftime(\"%H:%M:%S\")\n",
    "\n",
    "# middleware hooks onto function invocation events\n",
    "async def logging_function_middleware(\n",
    "    context: FunctionInvocationContext,\n",
    "    next: Callable[[FunctionInvocationContext], Awaitable[None]],\n",
    ") -> None:\n",
    "    \"\"\"Middleware that logs function execution.\"\"\"\n",
    "    print(f\"[Function] Calling {context.function.name}\")\n",
    "\n",
    "    await next(context) # executes the actual function or any next MW\n",
    "\n",
    "    print(f\"[Function] {context.function.name} completed\")\n",
    "    print(f\"[Function] Result: {context.result}\")\n",
    "\n",
    "\n",
    "# agent-level MW is applied to the entire agent run\n",
    "@agent_middleware  # Explicitly marks as agent middleware\n",
    "async def logging_agent_middleware(context, next):    # don't need to explicitly declare type annotations\n",
    "    \"\"\"Agent middleware with decorator - types are inferred.\"\"\"\n",
    "    print(f\"[Agent] BEFORE execution\")\n",
    "    await next(context)     # executes the agent logic\n",
    "    print(f\"[Agent] AFTER execution | Agent output: {context.result}\")\n",
    "\n",
    "agent = client.create_agent(\n",
    "    name=\"TimeAgent\",\n",
    "    instructions=\"You can tell the current time.\",\n",
    "    tools=[get_time],    \n",
    "    middleware=[logging_function_middleware, logging_agent_middleware]\n",
    ")\n",
    "\n",
    "result = await agent.run(\"What time is it?\")\n",
    "print(\"Final response: \", result.text)\n",
    "\n",
    "print(\"----------------------------------\")\n",
    "\n",
    "# the following response doesn't invoke get_time() so logging_function MW won't fire\n",
    "result = await agent.run(\n",
    "    \"Can you help?\"\n",
    ")\n",
    "\n",
    "print(\"Final response: \", result.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c651f7e6",
   "metadata": {},
   "source": [
    "### Example from SK where logging was added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7aee3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated, List, Optional\n",
    "\n",
    "class LightModel(TypedDict):\n",
    "    id: int\n",
    "    name: str\n",
    "    is_on: bool | None\n",
    "    brightness: int | None\n",
    "    hex: str | None\n",
    "\n",
    "class LightsTools:\n",
    "    def __init__(self, lights: list[LightModel]): # stores a list of lights in self.lights\n",
    "        self.lights = lights\n",
    "\n",
    "    def get_lights(self) -> List[LightModel]:                \n",
    "        \"\"\"Gets a list of lights and their current state.\"\"\"\n",
    "        return self.lights\n",
    "\n",
    "    def get_state(\n",
    "        self, id: Annotated[int, \"The ID of the light\"] #  Annotated adds documentation for LLMs\n",
    "    ) -> Optional[LightModel]:\n",
    "        \"\"\"Gets the state of a particular light.\"\"\"\n",
    "        for light in self.lights:\n",
    "            if light[\"id\"] == id:\n",
    "                return light\n",
    "        return None\n",
    "    \n",
    "    def change_state(\n",
    "        self, id: Annotated[int, \"The ID of the light\"], new_state: LightModel\n",
    "    ) -> dict:\n",
    "        \"\"\"Changes the state of the light and returns previous/current info.\"\"\"\n",
    "        for light in self.lights:\n",
    "            if light[\"id\"] == id:\n",
    "                previous = light.copy()  # snapshot before change\n",
    "                light[\"is_on\"] = new_state.get(\"is_on\", light[\"is_on\"])\n",
    "                light[\"brightness\"] = new_state.get(\"brightness\", light[\"brightness\"])\n",
    "                light[\"hex\"] = new_state.get(\"hex\", light[\"hex\"])\n",
    "                return {\n",
    "                    \"previous\": previous,\n",
    "                    \"current\": light\n",
    "                }\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9dcfcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "lights = [\n",
    "    {\"id\": 1, \"name\": \"Table Lamp\", \"is_on\": False, \"brightness\": 100, \"hex\": \"FF0000\"},\n",
    "    {\"id\": 2, \"name\": \"Porch light\", \"is_on\": False, \"brightness\": 50, \"hex\": \"00FF00\"},\n",
    "    {\"id\": 3, \"name\": \"Chandelier\", \"is_on\": True, \"brightness\": 75, \"hex\": \"0000FF\"},\n",
    "]\n",
    "\n",
    "# data to instantiate a class and pass methods as tools\n",
    "tools = LightsTools(lights=lights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f8ebc54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have turned on the Table Lamp and the Porch light, which were previously off. The Chandelier was already on, so no action was needed for it.\n",
      "Final data: [{'id': 1, 'name': 'Table Lamp', 'is_on': True, 'brightness': 100, 'hex': 'FF0000'}, {'id': 2, 'name': 'Porch light', 'is_on': True, 'brightness': 50, 'hex': '00FF00'}, {'id': 3, 'name': 'Chandelier', 'is_on': True, 'brightness': 75, 'hex': '0000FF'}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "agent = client.create_agent(\n",
    "    instructions=\"\"\"\n",
    "    You control and manage smart lights.\n",
    "    - Check previous states to check if an action needs to be taken\n",
    "    - When turning lights on or off, do NOT change brightness or hex unless the user explicitly asks.\n",
    "    - When changing brightness or hex, only modify those values if requested.\"\"\",\n",
    "    tools=[tools.get_lights, tools.get_state, tools.change_state]\n",
    ")\n",
    "\n",
    "result = await agent.run(\n",
    "    \"turn on all lamps\",\n",
    "    )\n",
    "\n",
    "print(result)\n",
    "print(\"Final data:\", tools.lights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a948d9",
   "metadata": {},
   "source": [
    "In the following exercise, we'll be adding middleware for easier debugging and understanding of agent behavior, because currently we can't see anything besides agent's response.\n",
    "We'll add function middleware which intercepts function calls within agents, chat middleware dor OpenAI usage logging and agent-level middleware which is persistent across all runs for tool call counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aec56a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-27 19:40:58,673 - INFO - [Agent] Starting execution\n",
      "2025-10-27 19:40:58,676 - INFO - [Chat] Sending 2 messages to AI\n",
      "2025-10-27 19:41:00,238 - INFO - HTTP Request: POST https://semantic-kernel1.openai.azure.com/openai/deployments/sk-gpt-4o-mini/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-10-27 19:41:00,243 - INFO - [Chat] Response received\n",
      "2025-10-27 19:41:00,245 - INFO - [Function] Calling - get_lights | Args: \n",
      "2025-10-27 19:41:00,248 - INFO - Function name: get_lights\n",
      "2025-10-27 19:41:00,249 - INFO - Function get_lights succeeded.\n",
      "2025-10-27 19:41:00,251 - INFO - [Function] Completed \"get_lights\" in 0.003227s | Result: [{'id': 1, 'name': 'Table Lamp', 'is_on': True, 'brightness': 100, 'hex': 'FF0000'}, {'id': 2, 'name': 'Porch light', 'is_on': True, 'brightness': 50, 'hex': '00FF00'}, {'id': 3, 'name': 'Chandelier', 'is_on': True, 'brightness': 75, 'hex': '0000FF'}]\n",
      "2025-10-27 19:41:00,253 - INFO - [Chat] Sending 4 messages to AI\n",
      "2025-10-27 19:41:02,386 - INFO - HTTP Request: POST https://semantic-kernel1.openai.azure.com/openai/deployments/sk-gpt-4o-mini/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-10-27 19:41:02,389 - INFO - [Chat] Response received\n",
      "2025-10-27 19:41:02,391 - INFO - [Function] Calling - change_state | Args: id=1 new_state={'id': 1, 'name': 'Table Lamp', 'is_on': False, 'brightness': 100, 'hex': 'FF0000'}\n",
      "2025-10-27 19:41:02,393 - INFO - Function name: change_state\n",
      "2025-10-27 19:41:02,395 - INFO - Function change_state succeeded.\n",
      "2025-10-27 19:41:02,398 - INFO - [Function] Completed \"change_state\" in 0.004447s | Result: {'previous': {'id': 1, 'name': 'Table Lamp', 'is_on': True, 'brightness': 100, 'hex': 'FF0000'}, 'current': {'id': 1, 'name': 'Table Lamp', 'is_on': False, 'brightness': 100, 'hex': 'FF0000'}}\n",
      "2025-10-27 19:41:02,400 - INFO - [Function] Calling - change_state | Args: id=2 new_state={'id': 2, 'name': 'Porch light', 'is_on': False, 'brightness': 50, 'hex': '00FF00'}\n",
      "2025-10-27 19:41:02,403 - INFO - Function name: change_state\n",
      "2025-10-27 19:41:02,405 - INFO - Function change_state succeeded.\n",
      "2025-10-27 19:41:02,407 - INFO - [Function] Completed \"change_state\" in 0.003963s | Result: {'previous': {'id': 2, 'name': 'Porch light', 'is_on': True, 'brightness': 50, 'hex': '00FF00'}, 'current': {'id': 2, 'name': 'Porch light', 'is_on': False, 'brightness': 50, 'hex': '00FF00'}}\n",
      "2025-10-27 19:41:02,408 - INFO - [Function] Calling - change_state | Args: id=3 new_state={'id': 3, 'name': 'Chandelier', 'is_on': False, 'brightness': 75, 'hex': '0000FF'}\n",
      "2025-10-27 19:41:02,410 - INFO - Function name: change_state\n",
      "2025-10-27 19:41:02,413 - INFO - Function change_state succeeded.\n",
      "2025-10-27 19:41:02,417 - INFO - [Function] Completed \"change_state\" in 0.006146s | Result: {'previous': {'id': 3, 'name': 'Chandelier', 'is_on': True, 'brightness': 75, 'hex': '0000FF'}, 'current': {'id': 3, 'name': 'Chandelier', 'is_on': False, 'brightness': 75, 'hex': '0000FF'}}\n",
      "2025-10-27 19:41:02,419 - INFO - [Chat] Sending 6 messages to AI\n",
      "2025-10-27 19:41:03,961 - INFO - HTTP Request: POST https://semantic-kernel1.openai.azure.com/openai/deployments/sk-gpt-4o-mini/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-10-27 19:41:03,963 - INFO - [Chat] Response received\n",
      "2025-10-27 19:41:03,965 - INFO - [Agent] Agent run completed in 5.2914s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant >All lights have been turned off. Here are their final states:\n",
      "\n",
      "1. **Table Lamp**\n",
      "   - Previous State: On\n",
      "   - Current State: Off\n",
      "   - Brightness: 100\n",
      "   - Hex: FF0000\n",
      "\n",
      "2. **Porch Light**\n",
      "   - Previous State: On\n",
      "   - Current State: Off\n",
      "   - Brightness: 50\n",
      "   - Hex: 00FF00\n",
      "\n",
      "3. **Chandelier**\n",
      "   - Previous State: On\n",
      "   - Current State: Off\n",
      "   - Brightness: 75\n",
      "   - Hex: 0000FF\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import time\n",
    "from agent_framework import function_middleware, agent_middleware, chat_middleware\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\", force=True\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "@agent_middleware       # decorator allows to skip type annotations like AgentRunContext\n",
    "async def agent_middleware(context,next                           \n",
    ") -> None:\n",
    "    start = time.perf_counter()\n",
    "\n",
    "    logger.info(f\"[Agent] Starting execution\")\n",
    "\n",
    "    await next(context)\n",
    "\n",
    "    # Calculate total duration\n",
    "    duration = time.perf_counter() - start\n",
    "    logger.info(f\"[Agent] Agent run completed in {duration:.4f}s\")\n",
    "\n",
    "@chat_middleware \n",
    "async def chat_middleware(context, next\n",
    ") -> None:\n",
    "    logger.info(f\"[Chat] Sending {len(context.messages)} messages to AI\")\n",
    "\n",
    "    await next(context)\n",
    "\n",
    "    logger.info(\"[Chat] Response received\")\n",
    "\n",
    "@function_middleware        \n",
    "async def function_middleware(context, next\n",
    ") -> None:\n",
    "    logger.info(f\"[Function] Calling - {context.function.name} | Args: {context.arguments}\")\n",
    "    start = time.perf_counter()\n",
    "\n",
    "    await next(context)\n",
    "\n",
    "    duration = time.perf_counter() - start\n",
    "    logger.info(f\"[Function] Completed \\\"{context.function.name}\\\" in {duration:.6f}s | Result: {context.result}\")\n",
    "\n",
    "\n",
    "agent = client.create_agent(\n",
    "    instructions=\"\"\"\n",
    "    You control and manage smart lights.\n",
    "    - Check previous states to check if an action needs to be taken\n",
    "    - When turning lights on or off, do NOT change brightness or hex unless the user explicitly asks.\n",
    "    - When changing brightness or hex, only modify those values if requested.\"\"\",\n",
    "    tools=[tools.get_lights, tools.get_state, tools.change_state],\n",
    "    middleware=[agent_middleware, chat_middleware, function_middleware]\n",
    ")\n",
    "\n",
    "result = await agent.run(\n",
    "    \"turn off all lights and give me their final state\"\n",
    "    )\n",
    "\n",
    "print(\"Assistant >\" + str(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70105f17",
   "metadata": {},
   "source": [
    "### Exercise: Create Your Own Function Tools\n",
    "*Based on SK's 2.1 \"Create Your Own Plugin\"*\n",
    "\n",
    "Now it's your turn to create a custom plugin and use it with an agent. Your plugin could simulate a database lookup, a translation service, or any other useful functionality.\n",
    "\n",
    "Your task:\n",
    "1. Create a custom plugin class with at least two kernel functions\n",
    "2. Add the plugin to the kernel\n",
    "3. Create an agent that uses your plugin\n",
    "4. Test the agent with appropriate queries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa6d4289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here to create a custom plugin\n",
    "\n",
    "# 1. Define your function tool class with kernel functions\n",
    "\n",
    "# 2. Create an instance and add it to the kernel\n",
    "\n",
    "# 3. Create an agent that can use your plugin\n",
    "\n",
    "# 4. Test the agent with appropriate queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "920e921e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User: What languages can you translate to?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-27 19:41:25,258 - INFO - HTTP Request: POST https://semantic-kernel1.openai.azure.com/openai/deployments/sk-gpt-4o-mini/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-10-27 19:41:25,259 - INFO - Function name: list_languages\n",
      "2025-10-27 19:41:25,260 - INFO - Function list_languages succeeded.\n",
      "2025-10-27 19:41:26,082 - INFO - HTTP Request: POST https://semantic-kernel1.openai.azure.com/openai/deployments/sk-gpt-4o-mini/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language Assistant: I can translate to the following languages: English, Spanish, French, German, Italian, Japanese, and Chinese.\n",
      "\n",
      "User: How do I say 'thank you' in French?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-27 19:41:27,390 - INFO - HTTP Request: POST https://semantic-kernel1.openai.azure.com/openai/deployments/sk-gpt-4o-mini/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-10-27 19:41:27,393 - INFO - Function name: translate\n",
      "2025-10-27 19:41:27,395 - INFO - Function translate succeeded.\n",
      "2025-10-27 19:41:28,064 - INFO - HTTP Request: POST https://semantic-kernel1.openai.azure.com/openai/deployments/sk-gpt-4o-mini/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language Assistant: In French, you say \"thank you\" as **\"merci.\"**\n",
      "\n",
      "User: Can you detect what language this is: 'Grazie mille'?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-27 19:41:29,375 - INFO - HTTP Request: POST https://semantic-kernel1.openai.azure.com/openai/deployments/sk-gpt-4o-mini/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n",
      "2025-10-27 19:41:29,379 - INFO - Function name: detect_language\n",
      "2025-10-27 19:41:29,380 - INFO - Function detect_language succeeded.\n",
      "2025-10-27 19:41:30,239 - INFO - HTTP Request: POST https://semantic-kernel1.openai.azure.com/openai/deployments/sk-gpt-4o-mini/chat/completions?api-version=2025-01-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language Assistant: The phrase \"Grazie mille\" is in Italian, which means \"Thank you very much.\"\n"
     ]
    }
   ],
   "source": [
    "# will be hidden in html, here for test and review\n",
    "\n",
    "from typing import Annotated\n",
    "\n",
    "class TranslationTool:\n",
    "    \"\"\"A tool that simulates a language translation service.\"\"\"\n",
    "    \n",
    "    # Dictionary of supported languages and their codes\n",
    "    _supported_languages = {\n",
    "        \"english\": \"en\",\n",
    "        \"spanish\": \"es\",\n",
    "        \"french\": \"fr\",\n",
    "        \"german\": \"de\",\n",
    "        \"italian\": \"it\",\n",
    "        \"japanese\": \"ja\",\n",
    "        \"chinese\": \"zh\",\n",
    "    }\n",
    "    \n",
    "    # Simple translation dictionary for common phrases (in a real plugin, this would use an API)\n",
    "    _translations = {\n",
    "        \"hello\": {\n",
    "            \"es\": \"hola\",\n",
    "            \"fr\": \"bonjour\",\n",
    "            \"de\": \"hallo\",\n",
    "            \"it\": \"ciao\",\n",
    "            \"ja\": \"こんにちは\",\n",
    "            \"zh\": \"你好\"\n",
    "        },\n",
    "        \"goodbye\": {\n",
    "            \"es\": \"adiós\",\n",
    "            \"fr\": \"au revoir\",\n",
    "            \"de\": \"auf wiedersehen\",\n",
    "            \"it\": \"arrivederci\",\n",
    "            \"ja\": \"さようなら\",\n",
    "            \"zh\": \"再见\"\n",
    "        },\n",
    "        \"thank you\": {\n",
    "            \"es\": \"gracias\",\n",
    "            \"fr\": \"merci\",\n",
    "            \"de\": \"danke\",\n",
    "            \"it\": \"grazie\",\n",
    "            \"ja\": \"ありがとう\",\n",
    "            \"zh\": \"谢谢\"\n",
    "        },\n",
    "        \"please\": {\n",
    "            \"es\": \"por favor\",\n",
    "            \"fr\": \"s'il vous plaît\",\n",
    "            \"de\": \"bitte\",\n",
    "            \"it\": \"per favore\",\n",
    "            \"ja\": \"お願いします\",\n",
    "            \"zh\": \"请\"\n",
    "        },\n",
    "        \"how are you\": {\n",
    "            \"es\": \"¿cómo estás?\",\n",
    "            \"fr\": \"comment allez-vous?\",\n",
    "            \"de\": \"wie geht es dir?\",\n",
    "            \"it\": \"come stai?\",\n",
    "            \"ja\": \"お元気ですか？\",\n",
    "            \"zh\": \"你好吗？\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "  \n",
    "    async def list_languages(self) -> str:\n",
    "        \"\"\"Return a list of languages supported by the translation service.\"\"\"\n",
    "        languages = list(self._supported_languages.keys())\n",
    "        return f\"Supported languages: {', '.join(languages)}\"\n",
    "    \n",
    "\n",
    "    async def translate(\n",
    "        self, \n",
    "        text: Annotated[str, \"The English text to translate.\"],\n",
    "        target_language: Annotated[str, \"The language to translate to.\"]\n",
    "    ) -> str:\n",
    "        \"\"\"Translate the given English text to the specified target language.\"\"\"\n",
    "        # Convert to lowercase for matching\n",
    "        text_lower = text.lower()\n",
    "        language_lower = target_language.lower()\n",
    "        \n",
    "        # Check if the target language is supported\n",
    "        if language_lower not in self._supported_languages:\n",
    "            return f\"Sorry, translation to {target_language} is not supported. Use list_languages() to see supported languages.\"\n",
    "        \n",
    "        # Get the language code\n",
    "        lang_code = self._supported_languages[language_lower]\n",
    "        \n",
    "        # Check if we have a translation for this phrase\n",
    "        for phrase, translations in self._translations.items():\n",
    "            if phrase in text_lower:\n",
    "                if lang_code in translations:\n",
    "                    # Replace the phrase with its translation\n",
    "                    translated = text.lower().replace(phrase, translations[lang_code])\n",
    "                    return f\"Translation to {target_language}: {translated}\"\n",
    "        \n",
    "        # For phrases we don't have stored, we'll simulate a generic response\n",
    "        return f\"Translation to {target_language} would normally be provided through an external API.\"\n",
    "    \n",
    "\n",
    "    async def detect_language(self, text: Annotated[str, \"The text to analyze.\"]) -> str:\n",
    "        \"\"\"Detect the likely language of the provided text.\"\"\"\n",
    "        text_lower = text.lower()\n",
    "        \n",
    "        # Simple detection based on known translations\n",
    "        for phrase, translations in self._translations.items():\n",
    "            for lang_code, translated_phrase in translations.items():\n",
    "                if translated_phrase in text_lower:\n",
    "                    # Get the language name from the code\n",
    "                    language = next(name for name, code in self._supported_languages.items() if code == lang_code)\n",
    "                    return f\"Detected language: {language.capitalize()}\"\n",
    "        \n",
    "        # Default response if no match found\n",
    "        return \"Language detection would normally use detailed analysis through an external API.\"\n",
    "\n",
    "tools = TranslationTool()\n",
    "\n",
    "# Create a language assistant\n",
    "language_agent = client.create_agent(\n",
    "    name=\"LanguageAssistant\",\n",
    "    instructions=\"\"\"You are a helpful language assistant that can help users with translations.\n",
    "    Use the available functions to provide translations and language information.\n",
    "    \n",
    "    When answering questions:\n",
    "    1. If a user wants to know what languages are supported, use the list_languages function\n",
    "    2. If a user wants a translation, use the translate function\n",
    "    3. If a user provides text in a foreign language, try to identify it with detect_language\n",
    "    4. Provide cultural context when relevant to the translation\n",
    "    \"\"\",\n",
    "    tools = [tools.list_languages, tools.translate, tools.detect_language]\n",
    ")\n",
    "\n",
    "thread = language_agent.get_new_thread()\n",
    "    \n",
    "# Test questions\n",
    "questions = [\n",
    "    \"What languages can you translate to?\",\n",
    "    \"How do I say 'thank you' in French?\",\n",
    "    \"Can you detect what language this is: 'Grazie mille'?\"\n",
    "]\n",
    "\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"\\nUser: {question}\")\n",
    "    response = await language_agent.run(question, thread=thread)\n",
    "    print(f\"Language Assistant: {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5c71a2",
   "metadata": {},
   "source": [
    "### TODO: Add the exercise from SK 1.1 \"Creating a Content Filter\"\n",
    "For adding middleware to agents"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent-framework-workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
